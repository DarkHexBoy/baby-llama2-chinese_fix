dataset_params:
  train_data_path: [
        './data/pretrain_data.bin'
        #'./data/baidubaike_563w.bin',
        #'./data/medical_book.bin',
        # './data/medical_encyclopedia.bin',
        # './data/medical_qa.bin',
        # './data/wiki.bin'
    ]
  valid_data_path: [
        './data/valid_data.bin'
    ]
  sft_data_path: './data/sft_data.csv'
  test_data_path: [
        'data/shibing624-medical-pretrain/pretrain/test_encyclopedia.json',
    ]
  
  sft_long_data_path_train: './data/sft_long_data_train.csv'
  sft_long_data_path_val: './data/sft_long_data_val.csv'

model_path: 'best.model'
merge_lora_to_save: False
merge_lora_on_load: False

train_params:
  use_deepspeed: False
  max_epoch: 2
  log_iters: 200
  save_iters: 200
  eval_iters: 200
  eval_only: False
  always_save_ckpt: True
  init_from: 'scratch'
  grad_accum_steps: 64
  batch_size: 4
  learning_rate: 0.0003
  weight_decay: 0.1
  beta1: 0.9
  beta2: 0.95
  grad_clip: 1.0
  decay_lr: True
  warmup_iters: 1000
  lr_decay_iters: 80000
  min_lr: 0.00001
  backend: 'nccl'
  device: 'cuda'
  compile: False
  optimizer_type: 'AdamW' # AdamW/GaLoreAdamW/GaLoreAdamW8bit/GaLoreAdafactor

  
fine_tuning_params:
  ft_type: 'full_ft'  # full_ft/lora/qlora 
  lora_mudule: 'linear'  # linear/embedding/all
  lora_attn_dim: 8
  lora_attn_alpha: 128
  lora_dropout: 0.0
  lora_r_dropout: 0.0

eval_params:
  max_new_tokens: 100
  temperature: 1.0
  top_p: 0.4
  top_k: 30
  seed: 1337
  shot: 0